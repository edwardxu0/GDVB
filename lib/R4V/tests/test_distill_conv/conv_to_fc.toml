[distillation]
maxmemory="8G"
threshold=0.95
cuda=true

[distillation.parameters]
epochs=5
learning_rate=0.01
momentum=0.9
weight_decay=0.0005
T=1.0
alpha=1.0

[distillation.data]
format="mnist"
batchsize=1000

[distillation.data.train]
shuffle=true

[distillation.data.train.teacher]
path="tmp/artifacts/mnist"

[distillation.data.train.student]
path="tmp/artifacts/mnist"

[distillation.data.validation]
shuffle=false

[distillation.data.validation.teacher]
path="tmp/artifacts/mnist"

[distillation.data.validation.student]
path="tmp/artifacts/mnist"

[distillation.teacher]
framework="onnx"
input_shape=[1, 1, 28, 28]
model="tests/networks/mnist/conv.onnx"

[[distillation.strategies.forall]]
layer_type="Convolutional"
strategy="drop_layer"

[[distillation.strategies.forall]]
layer_type="MaxPool"
strategy="drop_layer"

[distillation.student]
path="tmp/test_distill_conv/conv_to_fc.student.onnx"
